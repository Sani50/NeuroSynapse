

import pandas as pd

# Load the uploaded dataset
file_path = '/content/eeg_parkinson_data.csv'
data = pd.read_csv(file_path)

# Display the first few rows and basic information about the dataset
data.head(), data.info()

     
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 15100 entries, 0 to 15099
Data columns (total 13 columns):
 #   Column                         Non-Null Count  Dtype  
---  ------                         --------------  -----  
 0   Age                            15100 non-null  int64  
 1   Target                         15100 non-null  int64  
 2   Raw_Signal_Mean                15100 non-null  float64
 3   Magnitude_Mean                 15100 non-null  float64
 4   Phase_Mean                     15100 non-null  float64
 5   Gender_Male                    15100 non-null  bool   
 6   Clinical_Stage_Stage 2         15100 non-null  bool   
 7   Clinical_Stage_Stage 3         15100 non-null  bool   
 8   Clinical_Stage_Stage 4         15100 non-null  bool   
 9   Clinical_Stage_Stage 5         15100 non-null  bool   
 10  Condition_Label_On-Medication  15100 non-null  bool   
 11  Condition_Label_Rest Tremor    15100 non-null  bool   
 12  Condition_Label_Rigidity       15100 non-null  bool   
dtypes: bool(8), float64(3), int64(2)
memory usage: 707.9 KB
(   Age  Target  Raw_Signal_Mean  Magnitude_Mean  Phase_Mean  Gender_Male  \
 0   57       3         0.001308        0.025417    0.052668        False   
 1   76       1         0.001788        0.024581    0.036751         True   
 2   50       1         0.000671        0.024573    0.018569        False   
 3   77       2         0.003779        0.024392    0.052041         True   
 4   67       2         0.001008        0.024249    0.049647         True   
 
    Clinical_Stage_Stage 2  Clinical_Stage_Stage 3  Clinical_Stage_Stage 4  \
 0                   False                    True                   False   
 1                   False                   False                   False   
 2                   False                   False                   False   
 3                   False                    True                   False   
 4                   False                    True                   False   
 
    Clinical_Stage_Stage 5  Condition_Label_On-Medication  \
 0                   False                           True   
 1                   False                          False   
 2                    True                          False   
 3                   False                          False   
 4                   False                          False   
 
    Condition_Label_Rest Tremor  Condition_Label_Rigidity  
 0                        False                     False  
 1                        False                      True  
 2                        False                      True  
 3                        False                     False  
 4                        False                     False  ,
 None)

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, KFold
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l2
import matplotlib.pyplot as plt

# Step 1: Load the Dataset
file_path = '/content/eeg_parkinson_data.csv'  # Update with the path to your dataset in Colab
data = pd.read_csv(file_path)

# Step 2: Preprocess the Dataset
# Normalize numeric columns
numeric_columns = ['Age', 'Raw_Signal_Mean', 'Magnitude_Mean', 'Phase_Mean']
scaler = MinMaxScaler()
data[numeric_columns] = scaler.fit_transform(data[numeric_columns])

# Convert boolean columns to numeric (0/1)
boolean_columns = [col for col in data.columns if data[col].dtype == 'bool']
data[boolean_columns] = data[boolean_columns].astype(int)

# Prepare features (X) and target (y)
X = data.drop(columns=['Target']).values  # Features
y = data['Target'].values                 # Target

# Reshape X into a time-series format
timesteps = 10
num_samples = len(X) // timesteps  # Ensure data is divisible by timesteps
X = X[:num_samples * timesteps].reshape(num_samples, timesteps, -1)
y = y[:num_samples * timesteps].reshape(num_samples, timesteps).mean(axis=1)  # Aggregate target per sequence

# Step 3: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Define the LSTM Model with Regularization and Dropout
model = Sequential()

# Add LSTM layer with L2 regularization
model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]),
               kernel_regularizer=l2(0.01)))  # L2 regularization

# Add Dropout layer to reduce overfitting
model.add(Dropout(0.2))  # 20% of neurons will be dropped

# Add Dense output layer
model.add(Dense(1))  # Output layer for regression (single value prediction)

# Step 5: Compile the Model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Step 6: Add Early Stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Step 7: Train the Model
history = model.fit(
    X_train, y_train,
    validation_split=0.2,  # Reserve 20% of the training set for validation
    epochs=50,
    batch_size=32,
    callbacks=[early_stopping],
    verbose=1
)

# Evaluate the Model
loss, mae = model.evaluate(X_test, y_test, verbose=1)
print(f"Test Loss: {loss}")
print(f"Test MAE: {mae}")


# Step 9: (Optional) Plot Training History
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Step 10: Cross-Validation (Optional)
# Perform KFold cross-validation to better evaluate model generalization

kf = KFold(n_splits=5, shuffle=True, random_state=42)
cv_losses, cv_maes = [], []

for train_idx, val_idx in kf.split(X):
    X_train_cv, X_val_cv = X[train_idx], X[val_idx]
    y_train_cv, y_val_cv = y[train_idx], y[val_idx]

    # Rebuild the model for each fold
    model_cv = Sequential()
    model_cv.add(LSTM(50, input_shape=(X_train_cv.shape[1], X_train_cv.shape[2]), kernel_regularizer=l2(0.01)))
    model_cv.add(Dropout(0.2))
    model_cv.add(Dense(1))

    model_cv.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

    # Train the model
    model_cv.fit(X_train_cv, y_train_cv, epochs=50, batch_size=32, verbose=0, validation_data=(X_val_cv, y_val_cv), callbacks=[early_stopping])

    # Evaluate the model
    val_loss, val_mae = model_cv.evaluate(X_val_cv, y_val_cv, verbose=0)
    cv_losses.append(val_loss)
    cv_maes.append(val_mae)

# Print Cross-Validation results
print(f"Cross-Validation Losses: {cv_losses}")
print(f"Cross-Validation MAEs: {cv_maes}")
print(f"Average Cross-Validation Loss: {np.mean(cv_losses)}")
print(f"Average Cross-Validation MAE: {np.mean(cv_maes)}")

     
/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Epoch 1/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 3s 17ms/step - loss: 1.4690 - mae: 0.9812 - val_loss: 0.3426 - val_mae: 0.3121
Epoch 2/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.3298 - mae: 0.3031 - val_loss: 0.2773 - val_mae: 0.2782
Epoch 3/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.2675 - mae: 0.2694 - val_loss: 0.1918 - val_mae: 0.2029
Epoch 4/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.1889 - mae: 0.2071 - val_loss: 0.1325 - val_mae: 0.1282
Epoch 5/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.1477 - mae: 0.1701 - val_loss: 0.1079 - val_mae: 0.1101
Epoch 6/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.1203 - mae: 0.1431 - val_loss: 0.0959 - val_mae: 0.1117
Epoch 7/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.1090 - mae: 0.1481 - val_loss: 0.0788 - val_mae: 0.0901
Epoch 8/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0931 - mae: 0.1359 - val_loss: 0.0701 - val_mae: 0.0860
Epoch 9/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0827 - mae: 0.1277 - val_loss: 0.0616 - val_mae: 0.0804
Epoch 10/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0766 - mae: 0.1247 - val_loss: 0.0579 - val_mae: 0.0866
Epoch 11/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0754 - mae: 0.1379 - val_loss: 0.0585 - val_mae: 0.1033
Epoch 12/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0690 - mae: 0.1282 - val_loss: 0.0464 - val_mae: 0.0676
Epoch 13/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0592 - mae: 0.1125 - val_loss: 0.0427 - val_mae: 0.0624
Epoch 14/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0586 - mae: 0.1207 - val_loss: 0.0410 - val_mae: 0.0658
Epoch 15/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0562 - mae: 0.1169 - val_loss: 0.0476 - val_mae: 0.1098
Epoch 16/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0511 - mae: 0.1105 - val_loss: 0.0338 - val_mae: 0.0508
Epoch 17/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0491 - mae: 0.1107 - val_loss: 0.0327 - val_mae: 0.0556
Epoch 18/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.0446 - mae: 0.1045 - val_loss: 0.0307 - val_mae: 0.0544
Epoch 19/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0443 - mae: 0.1092 - val_loss: 0.0278 - val_mae: 0.0448
Epoch 20/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0403 - mae: 0.1011 - val_loss: 0.0260 - val_mae: 0.0425
Epoch 21/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0391 - mae: 0.0999 - val_loss: 0.0244 - val_mae: 0.0403
Epoch 22/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.0375 - mae: 0.1004 - val_loss: 0.0234 - val_mae: 0.0422
Epoch 23/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 1s 7ms/step - loss: 0.0392 - mae: 0.1095 - val_loss: 0.0229 - val_mae: 0.0465
Epoch 24/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0353 - mae: 0.0975 - val_loss: 0.0207 - val_mae: 0.0376
Epoch 25/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0338 - mae: 0.0996 - val_loss: 0.0205 - val_mae: 0.0450
Epoch 26/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0346 - mae: 0.1040 - val_loss: 0.0220 - val_mae: 0.0604
Epoch 27/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0316 - mae: 0.0975 - val_loss: 0.0177 - val_mae: 0.0351
Epoch 28/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.0304 - mae: 0.0969 - val_loss: 0.0164 - val_mae: 0.0308
Epoch 29/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - loss: 0.0302 - mae: 0.0980 - val_loss: 0.0158 - val_mae: 0.0301
Epoch 30/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 1s 10ms/step - loss: 0.0288 - mae: 0.0955 - val_loss: 0.0164 - val_mae: 0.0437
Epoch 31/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - loss: 0.0284 - mae: 0.0993 - val_loss: 0.0141 - val_mae: 0.0280
Epoch 32/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 12ms/step - loss: 0.0258 - mae: 0.0902 - val_loss: 0.0134 - val_mae: 0.0256
Epoch 33/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 0.0260 - mae: 0.0909 - val_loss: 0.0131 - val_mae: 0.0294
Epoch 34/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - loss: 0.0263 - mae: 0.0936 - val_loss: 0.0133 - val_mae: 0.0383
Epoch 35/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 1s 7ms/step - loss: 0.0270 - mae: 0.0977 - val_loss: 0.0144 - val_mae: 0.0531
Epoch 36/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0257 - mae: 0.0981 - val_loss: 0.0155 - val_mae: 0.0641
Epoch 37/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0264 - mae: 0.1007 - val_loss: 0.0133 - val_mae: 0.0514
Epoch 38/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0238 - mae: 0.0932 - val_loss: 0.0117 - val_mae: 0.0400
Epoch 39/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0226 - mae: 0.0893 - val_loss: 0.0133 - val_mae: 0.0595
Epoch 40/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0243 - mae: 0.0963 - val_loss: 0.0095 - val_mae: 0.0233
Epoch 41/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0208 - mae: 0.0861 - val_loss: 0.0097 - val_mae: 0.0312
Epoch 42/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0218 - mae: 0.0921 - val_loss: 0.0104 - val_mae: 0.0435
Epoch 43/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0191 - mae: 0.0844 - val_loss: 0.0101 - val_mae: 0.0427
Epoch 44/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0196 - mae: 0.0844 - val_loss: 0.0088 - val_mae: 0.0318
Epoch 45/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0180 - mae: 0.0792 - val_loss: 0.0098 - val_mae: 0.0472
Epoch 46/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0186 - mae: 0.0829 - val_loss: 0.0080 - val_mae: 0.0280
Epoch 47/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0185 - mae: 0.0840 - val_loss: 0.0086 - val_mae: 0.0400
Epoch 48/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0181 - mae: 0.0848 - val_loss: 0.0077 - val_mae: 0.0329
Epoch 49/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0165 - mae: 0.0815 - val_loss: 0.0075 - val_mae: 0.0323
Epoch 50/50
31/31 ━━━━━━━━━━━━━━━━━━━━ 0s 8ms/step - loss: 0.0175 - mae: 0.0819 - val_loss: 0.0088 - val_mae: 0.0496
10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0076 - mae: 0.0328 
Test Loss: 0.007662552874535322
Test MAE: 0.0338766947388649

Cross-Validation Losses: [0.3436591625213623, 0.29722440242767334, 0.3286944627761841, 0.33444055914878845, 0.31552645564079285]
Cross-Validation MAEs: [0.33086153864860535, 0.26765677332878113, 0.3013233244419098, 0.3036101758480072, 0.29713064432144165]
Average Cross-Validation Loss: 0.3239090085029602
Average Cross-Validation MAE: 0.30011649131774903

# Assuming you have already trained your model (e.g., `model.fit(X_train, y_train)`)

# Predict on the training set
y_train_pred = model.predict(X_train)

# Predict on the test set
y_test_pred = model.predict(X_test)

# Calculate performance metrics for both sets (e.g., Mean Absolute Error, R² Score)
from sklearn.metrics import mean_absolute_error, r2_score

# Train performance
train_mae = mean_absolute_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

# Test performance
test_mae = mean_absolute_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

# Print the results
print(f"Training MAE: {train_mae}")
print(f"Training R²: {train_r2}")
print(f"Test MAE: {test_mae}")
print(f"Test R²: {test_r2}")

# Check if there's a significant performance gap between training and test data
if train_r2 > test_r2:
    print("Potential overfitting: The model performs much better on the training data.")
else:
    print("No signs of overfitting: The model generalizes well to the test data.")

     
38/38 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step
10/10 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step 
Training MAE: 0.02086410395159627
Training R²: 0.9944844956547213
Test MAE: 0.02126845812165974
Test R²: 0.9949647315277826
No signs of overfitting: The model generalizes well to the test data.

import joblib
from tensorflow.keras.models import load_model

# Save the scaler
scaler_path = 'scaler_parkinsons.pkl'
joblib.dump(scaler, scaler_path)
print(f"Scaler saved to {scaler_path}")

# Save the model
model_path = 'lstm_model_parkinsons.h5'
model.save(model_path)
print(f"Model saved to {model_path}")

     
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Scaler saved to scaler_parkinsons.pkl
Model saved to lstm_model_parkinsons.h5

!pip install dash

     
Collecting dash
  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)
Collecting Flask<3.1,>=1.0.4 (from dash)
  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)
Collecting Werkzeug<3.1 (from dash)
  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)
Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.24.1)
Collecting dash-html-components==2.0.0 (from dash)
  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)
Collecting dash-core-components==2.0.0 (from dash)
  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)
Collecting dash-table==5.0.0 (from dash)
  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.5.0)
Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.32.3)
Collecting retrying (from dash)
  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)
Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (75.1.0)
Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)
Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)
Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)
Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)
Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (9.0.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (24.2)
Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (3.0.2)
Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.21.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.4.0)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.2.3)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.12.14)
Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.17.0)
Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 49.6 MB/s eta 0:00:00
Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)
Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)
Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)
Downloading flask-3.0.3-py3-none-any.whl (101 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 6.6 MB/s eta 0:00:00
Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 228.0/228.0 kB 14.9 MB/s eta 0:00:00
Downloading retrying-1.3.4-py3-none-any.whl (11 kB)
Installing collected packages: dash-table, dash-html-components, dash-core-components, Werkzeug, retrying, Flask, dash
  Attempting uninstall: Werkzeug
    Found existing installation: Werkzeug 3.1.3
    Uninstalling Werkzeug-3.1.3:
      Successfully uninstalled Werkzeug-3.1.3
  Attempting uninstall: Flask
    Found existing installation: Flask 3.1.0
    Uninstalling Flask-3.1.0:
      Successfully uninstalled Flask-3.1.0
Successfully installed Flask-3.0.3 Werkzeug-3.0.6 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4

import dash
from dash import dcc, html
from dash.dependencies import Input, Output, State
import plotly.graph_objs as go
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from collections import deque
import joblib

# Load pre-trained LSTM model
model = tf.keras.models.load_model("/content/lstm_park_model.h5")  # Replace with the actual path
scaler = joblib.load("/content/scaler_parkinson.pkl")  # Load the scaler used for feature scaling

# Initialize Dash app
app = dash.Dash(__name__)
app.title = "Parkinson's Prediction Dashboard"

# Initialize rolling data buffers for real-time prediction visualization
time_window = 50
time_series = deque(maxlen=time_window)
prediction_probabilities = deque(maxlen=time_window)
labels = deque(maxlen=time_window)

# Fill with initial data
for i in range(time_window):
    time_series.append(i)
    prediction_probabilities.append(0.5)  # Neutral probability
    labels.append("Low Risk")

# App layout
app.layout = html.Div([
    html.H1("Parkinson's Prediction Dashboard", style={'text-align': 'center', 'color': 'white'}),

    # Prediction visualization
    html.Div([
        html.H3("Real-Time Parkinson's Risk Prediction", style={'color': 'white'}),
        dcc.Graph(id="real-time-prediction", style={'height': '40vh'}),
        html.Div([
            html.Div("Current Risk Level:", style={'font-size': '20px', 'color': 'white'}),
            html.Div(id="current-risk", style={
                'font-size': '30px',
                'text-align': 'center',
                'padding': '10px',
                'color': 'white',
                'background-color': 'gray',
                'border-radius': '10px',
                'margin-top': '10px'
            })
        ], style={'text-align': 'center'})
    ]),

    # Data upload for predictions
    html.Div([
        html.H3("Upload Test Data for Predictions", style={'color': 'white'}),
        dcc.Upload(
            id="upload-data",
            children=html.Div(["Drag and Drop or ", html.A("Select Files")]),
            style={
                'width': '100%',
                'height': '60px',
                'lineHeight': '60px',
                'borderWidth': '1px',
                'borderStyle': 'dashed',
                'borderRadius': '5px',
                'textAlign': 'center',
                'margin': '10px'
            },
            multiple=False
        ),
        html.Div(id="upload-status", style={'margin-top': '10px', 'text-align': 'center', 'color': 'white'})
    ]),

    # Real-time updates
    dcc.Interval(id="update-interval", interval=2000, n_intervals=0)  # Every 2 seconds
])

# Callback to update real-time predictions
@app.callback(
    [Output("real-time-prediction", "figure"),
     Output("current-risk", "children"),
     Output("current-risk", "style")],
    [Input("update-interval", "n_intervals")]
)
def update_real_time_predictions(n):
    # Generate synthetic real-time data for visualization
    num_features = model.input_shape[-1] * model.input_shape[1]
    test_data = np.random.uniform(-1, 1, size=(1, num_features))
    test_data = test_data.reshape(1, model.input_shape[1], model.input_shape[2])


    prob = model.predict(test_data)[0][0]
    risk_level = "High Risk" if prob > 0.5 else "Low Risk"

    # Update buffers
    time_series.append(time_series[-1] + 1)
    prediction_probabilities.append(prob)
    labels.append(risk_level)

    # Color map for risk level
    risk_color = "red" if risk_level == "High Risk" else "green"

    # Create real-time prediction figure
    prediction_figure = {
        "data": [
            go.Scatter(
                x=list(time_series),
                y=list(prediction_probabilities),
                mode="lines",
                name="Risk Probability",
                line=dict(color="white")  # Set line color to white
            )
        ],
        "layout": go.Layout(
            title="Real-Time Prediction",
            xaxis={"title": "Time", 'color': 'white'},
            yaxis={"title": "Probability of Parkinson's Risk", 'color': 'white'},
            yaxis_range=[0, 1],
            plot_bgcolor='black',  # Set plot background to black
            paper_bgcolor='black',  # Set the entire background to black
            font=dict(color='white'),  # Set font color to white
            showlegend=True
        )
    }

    # Update risk style
    risk_style = {
        'font-size': '30px',
        'text-align': 'center',
        'padding': '10px',
        'color': 'white',
        'background-color': risk_color,
        'border-radius': '10px',
        'margin-top': '10px'
    }

    return prediction_figure, risk_level, risk_style

# Callback to handle uploaded data
@app.callback(
    Output("upload-status", "children"),
    [Input("upload-data", "contents")],
    [State("upload-data", "filename"), State("upload-data", "last_modified")]
)
def handle_uploaded_data(contents, filename, last_modified):
    if contents is None:
        return "No file uploaded yet."

    # Process uploaded data (for simplicity, this example doesn't process files)
    return f"File '{filename}' uploaded successfully!"

# Run the app
if __name__ == "__main__":
    app.run_server(debug=True)

     
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
